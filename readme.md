
# Information

Something is informative if it reduces an observer’s uncertainty about the world. Consequently, something can only be informative when it exists in a greater context with other things which it can provide information about.

Contexts exist both physically and mentally — they are simply mediums which possess relationships between subsets/subspaces of themselves. A context is an individual state of some type of system — continuous or discrete. Often times, the entire state of the system is too complex to have full knowledge (or it’s continuous). In these cases, we only have partial information about the system’s state. However, we can additionally receive other partial states and gradually gain a better picture of the context, or we can learn patterns in states and eventually gain the ability to extract more information from partial states than was previously possible.

Uncertainty in a context arises from potential relationships between parts of the context that have not been ruled out. What constitutes a piece of information is subjective to an interpreter (aka relative to a context). It’s some type of signal which can enter the context and reduce its entropy.
